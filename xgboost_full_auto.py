import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import warnings
import time
import os
import pickle
warnings.filterwarnings('ignore')

class FullAutoXGBoostDemo:
    def __init__(self, data_path):
        self.data_path = data_path
        self.df = None
        self.X = None
        self.y = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.model = None
        self.label_encoder = LabelEncoder()
        self.gpu_available = self.check_gpu_availability()
        
    def check_gpu_availability(self):
        """æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨"""
        try:
            import subprocess
            result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
            if result.returncode == 0:
                print("âœ“ æ£€æµ‹åˆ°NVIDIA GPUï¼Œå°†å¯ç”¨GPUåŠ é€Ÿ")
                return True
            else:
                print("âš  æœªæ£€æµ‹åˆ°NVIDIA GPUï¼Œä½¿ç”¨CPUè®­ç»ƒ")
                return False
        except:
            print("âš  æ— æ³•æ£€æµ‹GPUçŠ¶æ€ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
            return False
    
    def load_and_explore_data(self):
        """åŠ è½½æ•°æ®å¹¶è¿›è¡Œåˆæ­¥æ¢ç´¢"""
        print("=== XGBoostå®Œå…¨è‡ªåŠ¨åŒ–æ¼”ç¤º - æ•°æ®åŠ è½½ ===")
        self.df = pd.read_csv(self.data_path)
        
        print(f"æ•°æ®é›†å½¢çŠ¶: {self.df.shape}")
        print(f"ç–¾ç—…ç±»å‹æ•°é‡: {self.df['Disease'].nunique()}")
        
        return self.df
    
    def preprocess_data(self):
        """æ•°æ®é¢„å¤„ç†"""
        print("\n=== æ•°æ®é¢„å¤„ç† ===")
        
        # è·å–ç—‡çŠ¶åˆ—
        symptom_columns = [col for col in self.df.columns if col.startswith('Symptom_')]
        print(f"ç—‡çŠ¶åˆ—æ•°é‡: {len(symptom_columns)}")
        
        # æ”¶é›†æ‰€æœ‰éç©ºçš„å”¯ä¸€ç—‡çŠ¶
        all_symptoms = set()
        for col in symptom_columns:
            symptoms_in_col = self.df[col].dropna().unique()
            all_symptoms.update([s.strip() for s in symptoms_in_col if pd.notna(s) and s.strip() != ''])
        
        all_symptoms = sorted(list(all_symptoms))
        print(f"æ€»å…±å‘ç° {len(all_symptoms)} ç§ä¸åŒç—‡çŠ¶")
        
        # åˆ›å»ºäºŒè¿›åˆ¶ç‰¹å¾çŸ©é˜µ
        feature_matrix = pd.DataFrame(0, index=self.df.index, columns=all_symptoms)
        
        for idx, row in self.df.iterrows():
            for col in symptom_columns:
                symptom_value = row[col]
                if pd.notna(symptom_value) and str(symptom_value).strip() != '':
                    symptom = str(symptom_value).strip()
                    if symptom in all_symptoms:
                        feature_matrix.loc[idx, symptom] = 1
        
        self.X = feature_matrix
        self.y = self.label_encoder.fit_transform(self.df['Disease'])
        
        print(f"ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {self.X.shape}")
        print(f"ç–¾ç—…ç±»åˆ«æ•°: {len(self.label_encoder.classes_)}")
        
        return self.X, self.y
    
    def split_data(self, test_size=0.2, random_state=42):
        """åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†"""
        print(f"\n=== æ•°æ®åˆ’åˆ† ===")
        
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            self.X, self.y, test_size=test_size, random_state=random_state, 
            stratify=self.y
        )
        
        print(f"è®­ç»ƒé›†å¤§å°: {self.X_train.shape}")
        print(f"æµ‹è¯•é›†å¤§å°: {self.X_test.shape}")
        
        return self.X_train, self.X_test, self.y_train, self.y_test
    
    def compare_training_methods(self):
        """å¯¹æ¯”ä¸åŒè®­ç»ƒæ–¹æ³•çš„æ€§èƒ½"""
        print("\n=== è®­ç»ƒæ–¹æ³•æ€§èƒ½å¯¹æ¯” ===")
        
        methods = []
        
        # æ–¹æ³•1: CPUåŸºç¡€è®­ç»ƒ
        cpu_params = {
            'objective': 'multi:softprob',
            'num_class': len(self.label_encoder.classes_),
            'eval_metric': 'mlogloss',
            'random_state': 42,
            'max_depth': 6,
            'learning_rate': 0.1,
            'n_estimators': 100,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'tree_method': 'hist',
            'verbosity': 0
        }
        
        print("\nğŸ–¥ï¸  æ–¹æ³•1: CPUåŸºç¡€è®­ç»ƒ")
        start_time = time.time()
        cpu_model = xgb.XGBClassifier(**cpu_params)
        cpu_model.fit(self.X_train, self.y_train)
        cpu_time = time.time() - start_time
        cpu_pred = cpu_model.predict(self.X_test)
        cpu_accuracy = accuracy_score(self.y_test, cpu_pred)
        
        methods.append({
            'name': 'CPUåŸºç¡€',
            'time': cpu_time,
            'accuracy': cpu_accuracy,
            'model': cpu_model
        })
        print(f"   è®­ç»ƒæ—¶é—´: {cpu_time:.2f}ç§’, å‡†ç¡®ç‡: {cpu_accuracy:.4f}")
        
        # æ–¹æ³•2: GPUè®­ç»ƒï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.gpu_available:
            gpu_params = cpu_params.copy()
            gpu_params.update({
                'tree_method': 'gpu_hist',
                'gpu_id': 0,
                'predictor': 'gpu_predictor'
            })
            
            print("\nğŸš€ æ–¹æ³•2: GPUåŠ é€Ÿè®­ç»ƒ")
            start_time = time.time()
            gpu_model = xgb.XGBClassifier(**gpu_params)
            gpu_model.fit(self.X_train, self.y_train)
            gpu_time = time.time() - start_time
            gpu_pred = gpu_model.predict(self.X_test)
            gpu_accuracy = accuracy_score(self.y_test, gpu_pred)
            
            methods.append({
                'name': 'GPUåŠ é€Ÿ',
                'time': gpu_time,
                'accuracy': gpu_accuracy,
                'model': gpu_model
            })
            print(f"   è®­ç»ƒæ—¶é—´: {gpu_time:.2f}ç§’, å‡†ç¡®ç‡: {gpu_accuracy:.4f}")
            
            # è®¡ç®—åŠ é€Ÿæ¯”
            if gpu_time > 0:
                speedup = cpu_time / gpu_time
                print(f"   GPUåŠ é€Ÿå€æ•°: {speedup:.2f}x")
        
        # æ–¹æ³•3: ä¼˜åŒ–å‚æ•°è®­ç»ƒ
        optimized_params = cpu_params.copy()
        optimized_params.update({
            'max_depth': 8,
            'learning_rate': 0.05,
            'n_estimators': 200,
            'subsample': 0.9,
            'colsample_bytree': 0.9,
            'reg_alpha': 0.1,
            'reg_lambda': 0.1
        })
        
        if self.gpu_available:
            optimized_params.update({
                'tree_method': 'gpu_hist',
                'gpu_id': 0,
                'predictor': 'gpu_predictor'
            })
        
        print("\nâš¡ æ–¹æ³•3: ä¼˜åŒ–å‚æ•°è®­ç»ƒ")
        start_time = time.time()
        opt_model = xgb.XGBClassifier(**optimized_params)
        opt_model.fit(self.X_train, self.y_train)
        opt_time = time.time() - start_time
        opt_pred = opt_model.predict(self.X_test)
        opt_accuracy = accuracy_score(self.y_test, opt_pred)
        
        methods.append({
            'name': 'ä¼˜åŒ–å‚æ•°',
            'time': opt_time,
            'accuracy': opt_accuracy,
            'model': opt_model
        })
        print(f"   è®­ç»ƒæ—¶é—´: {opt_time:.2f}ç§’, å‡†ç¡®ç‡: {opt_accuracy:.4f}")
        
        # é€‰æ‹©æœ€ä½³æ¨¡å‹
        best_method = max(methods, key=lambda x: x['accuracy'])
        self.model = best_method['model']
        
        print(f"\nğŸ† æœ€ä½³æ–¹æ³•: {best_method['name']}")
        print(f"   å‡†ç¡®ç‡: {best_method['accuracy']:.4f}")
        print(f"   è®­ç»ƒæ—¶é—´: {best_method['time']:.2f}ç§’")
        
        return methods, best_method
    
    def train_with_detailed_progress(self):
        """å¸¦è¯¦ç»†è¿›åº¦çš„è®­ç»ƒæ¼”ç¤º"""
        print("\n=== è¯¦ç»†è¿›åº¦è®­ç»ƒæ¼”ç¤º ===")
        
        params = {
            'objective': 'multi:softprob',
            'num_class': len(self.label_encoder.classes_),
            'eval_metric': 'mlogloss',
            'random_state': 42,
            'max_depth': 6,
            'learning_rate': 0.1,
            'n_estimators': 50,  # å‡å°‘è½®æ•°ä»¥ä¾¿å¿«é€Ÿæ¼”ç¤º
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'verbosity': 1
        }
        
        if self.gpu_available:
            params.update({
                'tree_method': 'gpu_hist',
                'gpu_id': 0,
                'predictor': 'gpu_predictor'
            })
            print("âœ“ ä½¿ç”¨GPUåŠ é€Ÿè®­ç»ƒ")
        else:
            params['tree_method'] = 'hist'
            print("ä½¿ç”¨CPUä¼˜åŒ–è®­ç»ƒ")
        
        progress_model = xgb.XGBClassifier(**params)
        
        print("\nå¼€å§‹è®­ç»ƒï¼Œæ˜¾ç¤ºæ¯5è½®è¿›åº¦...")
        start_time = time.time()
        
        # è®­ç»ƒå¹¶æ˜¾ç¤ºè¿›åº¦
        progress_model.fit(
            self.X_train, self.y_train,
            eval_set=[(self.X_train, self.y_train), (self.X_test, self.y_test)],
            verbose=5  # æ¯5è½®æ˜¾ç¤ºä¸€æ¬¡
        )
        
        training_time = time.time() - start_time
        print(f"\nâœ… è¯¦ç»†è¿›åº¦è®­ç»ƒå®Œæˆï¼è€—æ—¶: {training_time:.2f}ç§’")
        
        # è¯„ä¼°è¿›åº¦è®­ç»ƒæ¨¡å‹
        progress_pred = progress_model.predict(self.X_test)
        progress_accuracy = accuracy_score(self.y_test, progress_pred)
        print(f"è¿›åº¦è®­ç»ƒæ¨¡å‹å‡†ç¡®ç‡: {progress_accuracy:.4f}")
        
        return progress_model
    
    def evaluate_model(self):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        print("\n=== æ¨¡å‹æ€§èƒ½è¯„ä¼° ===")
        
        # é¢„æµ‹æ€§èƒ½æµ‹è¯•
        start_time = time.time()
        y_pred = self.model.predict(self.X_test)
        prediction_time = time.time() - start_time
        
        accuracy = accuracy_score(self.y_test, y_pred)
        print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"é¢„æµ‹è€—æ—¶: {prediction_time:.4f}ç§’")
        print(f"å¹³å‡æ¯æ ·æœ¬é¢„æµ‹æ—¶é—´: {prediction_time/len(self.X_test)*1000:.2f}ms")
        
        # æ‰¹é‡é¢„æµ‹æ€§èƒ½æµ‹è¯•
        print("\næ‰¹é‡é¢„æµ‹æ€§èƒ½æµ‹è¯•:")
        batch_sizes = [1, 10, 100, len(self.X_test)]
        
        for batch_size in batch_sizes:
            if batch_size > len(self.X_test):
                continue
                
            test_batch = self.X_test.iloc[:batch_size]
            
            start_time = time.time()
            predictions = self.model.predict(test_batch)
            batch_time = time.time() - start_time
            
            print(f"  æ‰¹é‡å¤§å° {batch_size:4d}: {batch_time*1000:6.2f}ms (å¹³å‡ {batch_time/batch_size*1000:6.2f}ms/æ ·æœ¬)")
        
        return accuracy
    
    def feature_importance_analysis(self):
        """ç‰¹å¾é‡è¦æ€§åˆ†æ"""
        print("\n=== ç‰¹å¾é‡è¦æ€§åˆ†æ ===")
        
        # è·å–ç‰¹å¾é‡è¦æ€§
        feature_importance = pd.DataFrame({
            'feature': self.X.columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("Top 15 æœ€é‡è¦ç—‡çŠ¶:")
        for i, row in feature_importance.head(15).iterrows():
            print(f"  {i+1:2d}. {row['feature']:25s}: {row['importance']:.4f}")
        
        return feature_importance
    
    def predict_disease_batch(self, test_cases):
        """æ‰¹é‡ç–¾ç—…é¢„æµ‹æ¼”ç¤º"""
        print(f"\n=== æ‰¹é‡ç–¾ç—…é¢„æµ‹æ¼”ç¤º ===")
        
        for i, symptoms_list in enumerate(test_cases, 1):
            print(f"\n--- æµ‹è¯•æ¡ˆä¾‹ {i} ---")
            print(f"è¾“å…¥ç—‡çŠ¶: {symptoms_list}")
            
            # åˆ›å»ºç‰¹å¾å‘é‡
            feature_vector = pd.DataFrame(0, index=[0], columns=self.X.columns)
            
            valid_symptoms = []
            for symptom in symptoms_list:
                if symptom in self.X.columns:
                    feature_vector.loc[0, symptom] = 1
                    valid_symptoms.append(symptom)
            
            if not valid_symptoms:
                print("âŒ æ²¡æœ‰æœ‰æ•ˆç—‡çŠ¶ç”¨äºé¢„æµ‹")
                continue
            
            print(f"æœ‰æ•ˆç—‡çŠ¶: {valid_symptoms}")
            
            # é¢„æµ‹
            start_time = time.time()
            prediction_encoded = self.model.predict(feature_vector)[0]
            probabilities = self.model.predict_proba(feature_vector)[0]
            prediction_time = time.time() - start_time
            
            prediction = self.label_encoder.inverse_transform([prediction_encoded])[0]
            
            # è·å–æ¦‚ç‡æœ€é«˜çš„å‡ ä¸ªç–¾ç—…
            disease_names = self.label_encoder.classes_
            prob_df = pd.DataFrame({
                'disease': disease_names,
                'probability': probabilities
            }).sort_values('probability', ascending=False)
            
            print(f"ğŸ¯ é¢„æµ‹ç»“æœ: {prediction}")
            print(f"ğŸ”¥ ç½®ä¿¡åº¦: {probabilities[prediction_encoded]:.4f}")
            print(f"âš¡ é¢„æµ‹è€—æ—¶: {prediction_time*1000:.2f}ms")
            print(f"ğŸ“Š Top 3 å¯èƒ½ç–¾ç—…:")
            for j, row in prob_df.head(3).iterrows():
                print(f"   {j+1}. {row['disease']}: {row['probability']:.4f}")
    
    def performance_summary(self):
        """æ€§èƒ½æ€»ç»“"""
        print("\n" + "="*60)
        print("ğŸ‰ XGBoostç–¾ç—…é¢„æµ‹ç³»ç»Ÿæ€§èƒ½æ€»ç»“")
        print("="*60)
        
        # ç³»ç»Ÿä¿¡æ¯
        print(f"ğŸ’» è®¡ç®—ç¯å¢ƒ: {'GPUåŠ é€Ÿ' if self.gpu_available else 'CPUä¼˜åŒ–'}")
        print(f"ğŸ“Š æ•°æ®è§„æ¨¡: {self.X.shape[0]} æ ·æœ¬, {self.X.shape[1]} ç‰¹å¾")
        print(f"ğŸ¥ ç–¾ç—…ç±»åˆ«: {len(self.label_encoder.classes_)} ç§")
        
        # æ¨¡å‹æ€§èƒ½
        y_pred = self.model.predict(self.X_test)
        accuracy = accuracy_score(self.y_test, y_pred)
        print(f"ğŸ¯ æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
        
        # é¢„æµ‹é€Ÿåº¦
        start_time = time.time()
        self.model.predict(self.X_test[:100])
        speed_time = time.time() - start_time
        print(f"âš¡ é¢„æµ‹é€Ÿåº¦: {speed_time/100*1000:.2f}ms/æ ·æœ¬")
        
        print("\nâœ… ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼Œå¯ç”¨äºå®é™…ç–¾ç—…é¢„æµ‹ï¼")
    
    def save_model(self, model_path='trained_model.pkl'):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹å’Œç›¸å…³æ•°æ®"""
        print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜æ¨¡å‹åˆ° {model_path}...")
        
        model_data = {
            'model': self.model,
            'label_encoder': self.label_encoder,
            'symptoms_list': list(self.X.columns),
            'feature_names': list(self.X.columns),
            'model_info': {
                'accuracy': accuracy_score(self.y_test, self.model.predict(self.X_test)),
                'n_samples': self.X.shape[0],
                'n_features': self.X.shape[1],
                'n_diseases': len(self.label_encoder.classes_),
                'diseases': list(self.label_encoder.classes_),
                'training_time': time.strftime('%Y-%m-%d %H:%M:%S')
            }
        }
        
        with open(model_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"âœ… æ¨¡å‹å·²æˆåŠŸä¿å­˜åˆ° {model_path}")
        print(f"ğŸ“Š æ¨¡å‹ä¿¡æ¯: {model_data['model_info']['n_samples']} æ ·æœ¬, {model_data['model_info']['n_features']} ç‰¹å¾, {model_data['model_info']['n_diseases']} ç–¾ç—…")
        print(f"ğŸ¯ æ¨¡å‹å‡†ç¡®ç‡: {model_data['model_info']['accuracy']:.4f}")

# ä¸»æ¼”ç¤ºå‡½æ•°
def main():
    print("ğŸš€ XGBoostç–¾ç—…é¢„æµ‹ç³»ç»Ÿ - å®Œå…¨è‡ªåŠ¨åŒ–æ¼”ç¤º")
    print("ç‰¹æ€§: GPUåŠ é€Ÿ + å®æ—¶è¿›åº¦ + æ€§èƒ½å¯¹æ¯” + æ‰¹é‡é¢„æµ‹")
    print("="*60)
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    demo = FullAutoXGBoostDemo('dataset.csv')
    
    # 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
    demo.load_and_explore_data()
    demo.preprocess_data()
    demo.split_data()
    
    # 2. è®­ç»ƒæ–¹æ³•æ€§èƒ½å¯¹æ¯”
    methods, best_method = demo.compare_training_methods()
    
    # 3. è¯¦ç»†è¿›åº¦è®­ç»ƒæ¼”ç¤º
    demo.train_with_detailed_progress()
    
    # 4. æ¨¡å‹è¯„ä¼°
    demo.evaluate_model()
    
    # 5. ç‰¹å¾é‡è¦æ€§åˆ†æ
    demo.feature_importance_analysis()
    
    # 6. æ‰¹é‡é¢„æµ‹æ¼”ç¤º
    test_cases = [
        ['itching', 'skin_rash', 'nodal_skin_eruptions'],
        ['fever', 'cough', 'fatigue'],
        ['stomach_pain', 'nausea', 'vomiting'],
        ['chest_pain', 'shortness_of_breath'],
        ['headache', 'dizziness', 'blurred_vision'],
        ['muscle_pain', 'joint_pain', 'weakness']
    ]
    
    demo.predict_disease_batch(test_cases)
    
    # 7. æ€§èƒ½æ€»ç»“
    demo.performance_summary()
    
    # 8. ä¿å­˜æ¨¡å‹
    demo.save_model('trained_model.pkl')
    
    return demo

if __name__ == "__main__":
    model = main()